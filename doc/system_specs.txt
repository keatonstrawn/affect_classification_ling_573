This text file contains descriptions of the system specifications. In particular, it documents the expected inputs and
outputs for each component of the system. It may also give a brief description of what each component does.




Data Processor (data_processor.py):

This module defines the DataProcessor class, which is used to pull and clean the raw data. The data is read in from .csv
files that are either saved locally, or downloaded from GitHub. The raw data comes from 3 separate csv files, separated
into train, validation, and test data. Each file has 5 columns: id, text, HS, TR, AG. 'id' contains the unique
identification numbers for each tweet; 'text' contains the raw text of the tweet (this includes URLs, hashtags, emojis,
references to twitter accounts, slang and misspellings, etc.); HS is a binary (0 or 1) tag that indicates whether (1) or
not (0) the tweet is classified as hate speech; TR is a binary tag that indicates whether the tweet is targeted at an
individual (1) or a general group (0); AG is a binary tag that indicates whether (1) or not (0) the tweet is aggressive.

The DataProcessor cleans the text field in the raw data. It does so by making the following changes:
0. Adding a column to indicate the primary language the tweet is written in
1. Removing the URLs
2. Separating the hashtags from the text and storing them in a separate list
*3. Replacing slang and abbreviated terms with standard English/Spanish (If possible, need to check which resources are
    available to do this.)
4. Determining what percentage of the text is capital letters and storing that value, before lowercasing the text
5. Saving the counts of common punctuation symbols (!, ?, $, *) before removing punctuation from the text
6. Replacing '@user' references with the string 'user' and storing the original user ids in a separate list

The output will be a pandas dataframe with the following fields:

(index) id: int
raw_text: str
cleaned_text: str
language: str
HS: binary (0, 1)
TR: binary (0, 1)
AG: binary (0, 1)
hashtags: List[str]
user_ids: List[str]
percent_capitals: float
!_count: int
?_count: int
$_count: int
*_count: int


Note that the [symbol]_count columns above can change, based on the specified symbol list. The columns shown here are
the symbols that are selected by default.




Feature Engineering (feature_engineering.py):

This module defines the FeatureEngineering class, which takes in the output of the data cleaning process, accomplished
via the DataProcessor class, and generates an expanded dataframe with additional columns for each new feature that is
generated. There are two main methods in this module. First is the fit_transform method, which intakes the training data
in order to train the feature-generating helper methods, wherever such training is required. This method returns a
transformed version of the training data DataFrame, which contains additional columns for each of the new features. The
second main method is the transform method, which uses the trained helper methods from an earlier call to fit_transform
in order to transform the validation and test datasets to include the complete list of generated features for each
dataset.

The outputs of the fit_transform and transform methods will be transformed dataframes that contain each of the fields
mentioned above, as well as the following features:

NRC counts --> binary classification of words across eight emotional dimensions, then a positive dimension and a
                negative dimension. Raw counts are then transformed into proportions to normalize across tweets. This
                method adds ten new columns to the end of the dataframe: negative, positive, anger, anticipation,
                disgust, fear, joy, sadness, surprise, trust.

GloVe Embeddings --> Creates GloVe style embeddings using the cleaned_text. The embedding dimension is determined by the
                    version of glove.twitter that is specified by the embedding_filepath. Embeddings are generated for
                    each word in the text and then saved in a list under GloVe_embeddings. These embeddings are also
                    aggregated (using the component-wise mean) to generate a proxy for a 'sentence-level embedding' that
                    is stored in Aggregate_embeddings.

BERTweet Embeddings --> Creates BERT style embeddings using the cleaned_text. The embedding dimension is determined by the
                        embedding length of the BERTweet representations, typically 768 dimensions. Embeddings are generated for
                        each tweet, then saved under BERTweet_embeddings.

Universal Sentence Encoder Embeddings --> Creates embeddings generated using Google's Universal Sentence Encoder Embeddings.
                                        These embeddings have 512 dimensions, they are generated for each tweet, then are saved
                                        under Universal_Sentence_Encoder_embeddings.

Normalized Features --> A method to normalize the count features that were generated during the data cleaning process
                        was added. This method normalizes those counts to fall within [0,1] and is able to do so in two
                        different ways: min-max normalization or z-score normalization. The default behavior is to use
                        z-score normalization.
                            1. One option is to normalize with respect to the min-max range seen across the training
                                data for each feature. These min-max values are stored on the FeatureEngineering object
                                and used to scale unseen validation/test data. Any unseen data that falls outside of the
                                training min-max range is capped, to ensure the normalized values fall within [0,1].
                            2. The other option is to fit a normal distribution to the feature-specific counts in the
                                training data (by determining the standard deviation and mean) and converting the counts
                                to probabilities using the cdf.
                        The resulting values are stored under columns that follow the featureName_normalized structure.
                        The default behavior results in the following new columns: !_count_normalized,
                        ?_count_normalized, $_count_normalized, *_count_normalized.

*** MORE TO BE FILLED IN AS WE ADD NEW FEATURES ***



Classification Model (classification_model.py):

This module defines the ClassificationModel class, which takes in the output of the feature engineering process,
accomplished via the FeatureEngineering class, and uses the engineered features to train a model to predict the target
class for a given set of features. This is accomplished by first training the model by providing a training dataset that
includes gold-standard labels for the classification task of interest. Once a model is trained the predict method can
be used to make predictions with that model over a new dataset that contains all the features (except for the
gold-standard targets) used during model training.

Both the fit and predict methods will produce a dataframe that contains each of the original columns seen in the
provided data, as well as a new column (or columns) for each target the model predicted. The number of new columns and
datatype in each will depend on the classification model. The model types and affiliated prediction columns are listed
below. Note that these lists include all possible new columns, assuming that models were trained for all target
classification tasks. If a model is only trained for a subset of the classification tasks, then that model's fit and
predict methods will return dataframes that only contain the columns affiliated with the target classification tasks on
which the model was trained.

Model type: baseline, random_forest, svm
New columns:
    HS_prediction: boolean (0 or 1)
    TR_prediction: boolean (0 or 1)
    AG_prediction: boolean (0 or 1)

Model type: (None - anticipating adding more classification models in the future)
New columns:
    HS_0: float [0, 1]
    HS_1: float [0, 1]
    TR_0: float [0, 1]
    TR_1: float [0, 1]
    AG_0: float [0, 1]
    AG_1: float [0, 1]
    HS_prediction: boolean (0 or 1)
    TR_prediction: boolean (0 or 1)
    AG_prediction: boolean (0 or 1)



Model Evaluator (evaluator.py):
This module defines the Evaluator class, which takes the output of the classification and runs an analysis to evaluate the model's performance on the affect classification task. For each metric (HS, TR, AG), the evaluator calculates the precision, accuracy, and F1 scores achieved by the model. This class is an adaptation of the Evaluation script provided by the SemEval 2019 Task 5 team to ensure the same evaluation techniques were used by all teams participating in the shared task. It was then modified to be a class within our model. It requires a specific structure for the 'results' directory:
- 'results': directory containing all results-related content
    - 'input': directory containing the input information required by the Evaluator class for calculations
        - 'ref': directory containing the gold standard .tsv files for the data
        - 'res': directory containing the system results .tsv files for the data
    - 'output': directory containing the output file produced by the Evaluator class, containing F1, precision, and accuracy scores


Model Coordinator (main.py):
This file coordinates the system by loading the configuration file, and using it to consecutively run the system's modules from Processing to Feature Engineering to Classification to Evaluation. Additionally, this file has functions to format the data and store it in the correct files for the Model Evaluator to perform its analysis on the data.
